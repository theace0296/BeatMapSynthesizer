{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, TextIOWrapper, StringIO\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.pkl', 'rb') as f:\n",
    "    metadata_total = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_song_and_map(key):\n",
    "    \"\"\"Downloads the zipped folder of song and mapping data from the beatsaber api. Extracts files to a 'temp' folder \n",
    "    in the local directory.\"\"\"\n",
    "    response = requests.get(f\"https://beatsaver.com/api/download/key/{key}\")\n",
    "    if response.status_code == 200:\n",
    "        content_as_file = BytesIO(response.content)\n",
    "        zip_file = ZipFile(content_as_file)\n",
    "        for x in zip_file.filelist:\n",
    "            print(zip_file.extract(x.filename, path = 'temporary'))\n",
    "        return response.status_code\n",
    "    else:\n",
    "        return print(f\"API call failed at {key} with error code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_difficulties(metadata_record):\n",
    "    \"\"\"Gets the difficulty levels that are present for a song in a metadata record.\"\"\"\n",
    "    levels = []\n",
    "    for key, value in metadata_record['metadata']['difficulties'].items():\n",
    "        if value == True or value == 'True':\n",
    "            levels.append(key)\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/BSmapsynth-env/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "#Load music file, estimate beat frames, and compute chromagram\n",
    "    y, sr = librosa.load('./temporary/song.ogg')\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y_percussive,\n",
    "                                                 sr=sr,\n",
    "                                                 #trim = False,\n",
    "                                                 units = 'frames')\n",
    "                                                 #start_bpm = bpm)\n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harmonic,\n",
    "                                            sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_frames_and_chroma(song_path, bpm):\n",
    "\n",
    "    #Load music file, estimate beat frames, and compute chromagram\n",
    "    y, sr = librosa.load(song_path)\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y_percussive,\n",
    "                                                 sr=sr,\n",
    "                                                 trim = False,\n",
    "                                                 units = 'frames',\n",
    "                                                 start_bpm = bpm)\n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harmonic,\n",
    "                                            sr=sr)\n",
    "    return tempo, beat_frames, chromagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_number_and_chroma_v2(beat_frames, chromagram, beat_list):\n",
    "    \n",
    "    \n",
    "    #Add beat count to beat frames\n",
    "    beat_count = np.arange(0, len(beat_frames), 1)\n",
    "    \n",
    "    beat_numbers = pd.concat([pd.Series(beat_count, name = '_time'), pd.Series(beat_frames, name = 'frame_no')], axis = 1)\n",
    "    beat_numbers['frame_no'] = beat_numbers['frame_no'].astype(int)\n",
    "    \n",
    "    #Merge beat_list (i.e., beat numbers) into beat_frames\n",
    "    this = pd.merge(beats_list, beat_numbers, on = '_time', how = 'outer', sort = True).interpolate()\n",
    "    this['frame_no'] = round(this['frame_no'])\n",
    "    this['frame_no'] = this['frame_no'].astype(int)\n",
    "    this.drop_duplicates('frame_no', keep='first', inplace=True)\n",
    "    \n",
    "    beat_chroma = librosa.util.sync(chromagram,\n",
    "                                np.array(this['frame_no']),\n",
    "                                aggregate=np.median)\n",
    "    chroma_df = pd.DataFrame(beat_chroma.T)\n",
    "    chroma_df.drop(0, axis = 0, inplace = True)\n",
    "    chroma_df.reset_index(inplace = True, drop = True)\n",
    "    chroma_beat_number = pd.concat([this, chroma_df], axis = 1)\n",
    "    chroma_beat_number.drop('frame_no', axis = 1, inplace = True)\n",
    "    return chroma_beat_number\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_number_and_chroma(song_path, bpm):\n",
    "    \"\"\"This function reads in a music file and returns a DataFrame of beat numbers (divided into 1/16th beats) and\n",
    "    chroma features at each beat. Chroma features are calculated for 1/4 beats and propagated forward across the \n",
    "    16th beats.\"\"\"\n",
    "    #Load music file, estimate beat frames, and compute chromagram\n",
    "    y, sr = librosa.load(song_path)\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y_percussive,\n",
    "                                                 sr=sr,\n",
    "                                                 #trim = False,\n",
    "                                                 units = 'frames',\n",
    "                                                 start_bpm = bpm)\n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harmonic,\n",
    "                                            sr=sr)\n",
    "    #Make a framework for syncing chroma features to 1/4 beat\n",
    "    extend = np.array([])\n",
    "    ind = 0\n",
    "    while ind < len(beat_frames)-1:\n",
    "        extend = np.append(extend, np.arange(beat_frames[ind], beat_frames[ind+1], round((beat_frames[ind+1]-beat_frames[ind])/4))[1:4])\n",
    "        ind += 1\n",
    "    beat_frames_merged = np.concatenate((np.array([0]), beat_frames, extend))\n",
    "    beat_frames_merged.sort()\n",
    "    \n",
    "    #Sync chroma features to 1/4 beats\n",
    "    beat_chroma = librosa.util.sync(chromagram,\n",
    "                                beat_frames_merged.astype(int),\n",
    "                                aggregate=np.median)\n",
    "    \n",
    "    #Add beat count to beat frames\n",
    "    t = np.arange(0, len(beat_frames), 1)\n",
    "    beat_numbers = pd.concat([pd.Series(t, name = '_time'), pd.Series(beat_frames, name = 'frame_no')], axis = 1)\n",
    "    beat_numbers['frame_no'] = beat_numbers['frame_no'].astype(int)\n",
    "    \n",
    "    #Merge chroma features with extended beat frames (1/4 beat)\n",
    "    chromabeats = pd.concat([pd.Series(beat_frames_merged.astype(int), name = 'frame_no'), pd.DataFrame(beat_chroma.T)], axis = 1)\n",
    "    z = pd.merge(beat_numbers, chromabeats, on = 'frame_no', how = 'outer', sort = True)\n",
    "    z.interpolate(inplace = True)\n",
    "    \n",
    "    #Expand beat frequency to 1/16th beat & merge\n",
    "    expand_time = pd.DataFrame(np.arange(0.00, z['_time'].max(), 0.0625), columns = ['_time'])\n",
    "    expanded_chromabeats = pd.merge(z, expand_time, on='_time', how = 'outer', sort = True)\n",
    "    \n",
    "    #Forward fill to fill NaNs\n",
    "    expanded_chromabeats.fillna(method='ffill', inplace = True)\n",
    "    expanded_chromabeats.drop('frame_no', axis = 1, inplace = True)\n",
    "    \n",
    "    return tempo, expanded_chromabeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_processing(mapfile):\n",
    "    \"\"\"This function extracts the notes list from the mapfile and transforms it into a DataFrame of note features\n",
    "    at 16th beat time points.\"\"\"\n",
    "    notes = pd.DataFrame.from_dict(mapfile['_notes']).add_prefix('notes')\n",
    "    wide = widen_notes(notes)\n",
    "#     long = to_sixteenth_beat(wide)\n",
    "    return wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widen_notes(notes):\n",
    "    \"\"\"This function takes a DataFrame containing all the notes (i.e., blocks) from a level.dat file and widens\n",
    "    the DataFrame such that one time point has seperate columns for each type of block.\"\"\"\n",
    "    wide = None\n",
    "    x = 0\n",
    "    while x < len(notes['notes_type'].unique()):\n",
    "        if x == 0:\n",
    "            #Make separate dataframe for first note type and add a suffix for the column names\n",
    "            notes_a = notes[notes['notes_type'] == notes['notes_type'].unique()[x]].reset_index()\n",
    "            notes_a.drop('index', axis = 1, inplace=True)\n",
    "            notes_a = notes_a.add_suffix(f\"_{notes['notes_type'].unique()[x]}\")\n",
    "            notes_a['_time'] = notes_a[f\"notes_time_{notes['notes_type'].unique()[x]}\"]\n",
    "            notes_a.drop(f\"notes_time_{notes['notes_type'].unique()[x]}\", axis = 1, inplace = True)\n",
    "            #Do the process again for the second note type\n",
    "            notes_b = notes[notes['notes_type'] == notes['notes_type'].unique()[x+1]].reset_index()\n",
    "            notes_b.drop('index', axis = 1, inplace=True)\n",
    "            notes_b = notes_b.add_suffix(f\"_{notes['notes_type'].unique()[x+1]}\")\n",
    "            notes_b['_time'] = notes_b[f\"notes_time_{notes['notes_type'].unique()[x+1]}\"]\n",
    "            notes_b.drop(f\"notes_time_{notes['notes_type'].unique()[x+1]}\", axis = 1, inplace = True)\n",
    "            #Merge the two dataframes\n",
    "            wide = pd.merge(notes_a, notes_b, on = '_time', how = 'outer', sort = True)\n",
    "            x += 2\n",
    "        else: \n",
    "            #Continue adding and merging until all note types have been merged\n",
    "            notes_c = notes[notes['notes_type'] == notes['notes_type'].unique()[x]].reset_index()\n",
    "            notes_c.drop('index', axis = 1, inplace=True)\n",
    "            notes_c = notes_c.add_suffix(f\"_{notes['notes_type'].unique()[x]}\")\n",
    "            notes_c['_time'] = notes_c[f\"notes_time_{notes['notes_type'].unique()[x]}\"]\n",
    "            notes_c.drop(f\"notes_time_{notes['notes_type'].unique()[x]}\", axis = 1, inplace = True)\n",
    "            wide = pd.merge(wide, notes_c, on = '_time', how = 'outer', sort = True)\n",
    "            x += 1\n",
    "    #Replace NaN with 999\n",
    "    wide.fillna(999, inplace = True)\n",
    "    #Coerce all columns except _time back to integer\n",
    "    for column in wide.columns:\n",
    "        if column != '_time':\n",
    "            wide[column] = wide[column].astype(int)\n",
    "    return wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sixteenth_beat(notes_df):\n",
    "    \"\"\"This function expands the notes DataFrame to represent beats down to the sixteenth beat. Returns expanded \n",
    "    DataFrame with NaNs filled with 999.\"\"\"\n",
    "    song_len = notes_df['_time'].max()\n",
    "    expand_time = pd.DataFrame(np.arange(0.00, song_len, 0.0625), columns = ['_time'])\n",
    "    expanded_notes = pd.merge(notes_df, expand_time, on='_time', how = 'outer', sort = True)\n",
    "    #Replace NaN with 999\n",
    "    expanded_notes.fillna(999, inplace = True)\n",
    "    #Coerce all columns except _time back to integer\n",
    "    for column in expanded_notes.columns:\n",
    "        if column != '_time':\n",
    "            expanded_notes[column] = expanded_notes[column].astype(int)\n",
    "    return expanded_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process(metadata):\n",
    "    \"\"\"This is the master function that downloads the zipped folder with music, map, and info files. It extracts\n",
    "    features from the files and makes a single record out of the features.\"\"\"\n",
    "    #Construct list of download keys from metadata\n",
    "    key_list = []\n",
    "    for x in metadata:\n",
    "        key_list.append(x['key'])\n",
    "    \n",
    "    #For each dowload key in the metadata, download and process the zip folder\n",
    "    for key in key_list:\n",
    "        available_difficulties = get_available_difficulties(list(filter(lambda x: x['key'] == key, metadata))[0])\n",
    "        print(f\"{key}:\", available_difficulties)\n",
    "        code = download_song_and_map(key)\n",
    "        if code != 200:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                #open music file and process\n",
    "                with open('./temporary/info.dat', 'rb') as i:\n",
    "                    info = json.load(i)\n",
    "                music_path = info['_songFilename']\n",
    "                bpm = info['_beatsPerMinute']\n",
    "                tempo, beat_frames, chromagram = beat_frames_and_chroma(music_path, bpm)\n",
    "                \n",
    "                #open map files and process\n",
    "                for difficulty in available_difficulties:\n",
    "                    map_file = open_map_file(difficulty)\n",
    "                    notes_df = notes_processing(map_file)                    \n",
    "                    notes_df['_time'] = round(notes_df['_time'], 3)\n",
    "                    music_df = beat_number_and_chroma_v2(beat_frames, chromagram, notes_df['_time'])\n",
    "                    df = pd.merge(music_df, notes_df, on = '_time', how = 'outer', sort = True)\n",
    "                    df.iloc[:, 1:13] = df.iloc[:, 1:13].fillna(method = 'bfill', axis = 0)\n",
    "                    df.iloc[:, 13:] = df.iloc[:, 13:].fillna(value = 999, axis = 0)\n",
    "                    with open(f\"./fresh_level_df/{key}_{difficulty}.pkl\", 'wb') as f:\n",
    "                        pickle.dump(df, f)\n",
    "                    \n",
    "            except Exception as err:\n",
    "                 print(f\"{key}: \\n {err}\")\n",
    "            finally:\n",
    "                #delete temp directory\n",
    "                shutil.rmtree('./temporary/')\n",
    "        \n",
    "        \n",
    "        \n",
    "#         filelist = [f for f in os.listdir('temp')]\n",
    "#         for f in filelist:\n",
    "#             os.remove(os.path.join('temp', f))\n",
    "#         os.rmdir('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_map_file(difficulty):\n",
    "    \"\"\"This function opens the map file listed in the info.dat file for the specificed difficulty level.\"\"\"\n",
    "    with open('./temporary/info.dat', 'rb') as i:\n",
    "        info = json.load(i)\n",
    "    for x in info['_difficultyBeatmapSets']:\n",
    "        if x['_beatmapCharacteristicName'].casefold() == 'Standard'.casefold():\n",
    "            for y in x['_difficultyBeatmaps']:\n",
    "                if y['_difficulty'].casefold() == difficulty.casefold():\n",
    "                    file_name = y['_beatmapFilename']\n",
    "                    with open(f\"./temporary/{file_name}\", 'rb') as f:\n",
    "                        map_file = json.load(f)\n",
    "                    return map_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_songs = list(filter(lambda x: x['stats']['rating'] >= .9, metadata_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7a64: ['easy', 'expert', 'expertPlus', 'hard', 'normal']\n",
      "temporary/EasyStandard.dat\n",
      "temporary/NormalStandard.dat\n",
      "temporary/HardStandard.dat\n",
      "temporary/ExpertStandard.dat\n",
      "temporary/ExpertPlusStandard.dat\n",
      "temporary/cover.jpg\n",
      "temporary/song.egg\n",
      "temporary/info.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/BSmapsynth-env/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/BSmapsynth-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1089: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "download_and_process(good_songs[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSmapsynth-env",
   "language": "python",
   "name": "bsmapsynth-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
