{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, TextIOWrapper, StringIO\n",
    "from zipfile import ZipFile\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.chdir(\"../src/\")\n",
    "\n",
    "from download_and_process import download_and_process\n",
    "\n",
    "os.chdir(\"../notebooks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Processing\n",
    "\n",
    "This notebook contains the instructions for downloading and processing the data for training the Hidden Markov Models for BeatMapSynth. I do not suggest using this code because it can take over 24 hours to run, but rather download the zipped folder I have made available [here](https://drive.google.com/open?id=18l7p0K_gwRQ4NSVnuRGlqcM95TFsdbi6) and unzip the contents in the `data/processed_data/` folder of the repo.\n",
    "\n",
    "_If you insist though..._\n",
    "\n",
    "First, import the metadata from beatsaver.com that contain the download keys needed for making API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/metadata.pkl', 'rb') as f:\n",
    "    metadata_total = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, I trained my Hidden Markov Models on two sets of data.\n",
    "1. Custom maps with > 90% rating on beatsaver.com\n",
    "2. Custom maps with > 70% rating on beatsaver.com\n",
    "\n",
    "\n",
    "For the first set, subset the metadata with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_set = list(filter(lambda x: x['stats']['rating'] >= .9, metadata_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if you wanted to download and process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_process(first_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained my first model before downloading the second set, so you could go over to the modeling notebook and do that before proceeding to the next step. (In theory you could do all of the downloading at once and then train on the subset that is rated 90% or higher first, but that's just not the order I did things).\n",
    "\n",
    "After you've trained the first HMM, download the second dataset. This one will take a really long time. AGAIN, I DO NOT SUGGEST THIS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_set = list(filter(lambda x: x['stats']['rating'] < .9 and x['stats']['rating'] >= .7, metadata_total))\n",
    "download_and_process(second_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSmapsynth-env",
   "language": "python",
   "name": "bsmapsynth-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
