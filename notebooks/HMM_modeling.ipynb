{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import markovify\n",
    "import os\n",
    "\n",
    "os.chdir(\"../src/\")\n",
    "\n",
    "from HMM_modeling import HMM, make_sequence, train_HMM\n",
    "\n",
    "os.chdir(\"../notebooks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model Development\n",
    "\n",
    "This notebook can be used to train the Hidden Markov Models (HMM) for BeatMapSynth. If you do not wish to train them yourself, you can download them [here](https://drive.google.com/open?id=1p7j0sENy0DzcMHd3iQ_LQw14j6OcKLsY), unzip the folder, and place them in the `models/` directory.\n",
    "\n",
    "There are two sets of models based on data explained in the Data Acquisition and Processing notebook. When I developed these, I trained on the smaller set first, and then downloaded the larger, second dataset (which overlaps with the first). \n",
    "\n",
    "__If you have downloaded the data for the first dataset following the instructions from the Data Acquisition and Processing notebook and came here to follow the instructions to train the first model, run the following code.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code *only* if you downloaded and processed the first dataset using the code in the notebook, *NOT* if\n",
    "#you downloaded the data with the download link!\n",
    "difficulties = ['easy', 'normal', 'hard', 'expert', 'expertPlus']\n",
    "for difficulty in difficulties:\n",
    "    MC = HMM(difficulty)\n",
    "    with open(f\"../models/HMM_{difficulty}.pkl\", 'wb') as f:\n",
    "        pickle.dump(MC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you downloaded the processed data with the link provided, follow these instructions instead:__\n",
    "\n",
    "For you to train the first version independently, we'll have to subset the dataset first and generate the corpus from that for training the model. The out-of-the-box functions I made won't work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the metadata file with all of the download keys\n",
    "with open('../data/metadata.pkl', 'rb') as f:\n",
    "    metadata_total = pickle.load(f)\n",
    "#Subset the metadata to only maps with > 90% ratings\n",
    "first_set = list(filter(lambda x: x['stats']['rating'] >= .9, metadata_total))\n",
    "#Extract the download keys from the metadata\n",
    "first_set_keys = []\n",
    "for x in first_set:\n",
    "    first_set_keys.append(x['key'])\n",
    "#Make a list of files that are in the top 90%    \n",
    "first_set_filenames = []\n",
    "filelist = [f for f in os.listdir('../data/processed_data/')]\n",
    "for f in filelist:\n",
    "    split = f.split('_')\n",
    "    if split[0] in first_set_keys:\n",
    "        first_set_filenames.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can train the Hidden Markov Model for each difficulty level and save:\n",
    "difficulties = ['easy', 'normal', 'hard', 'expert', 'expertPlus']\n",
    "for difficulty in difficulties:\n",
    "    corpus = []\n",
    "    for f in first_set_filenames:\n",
    "        if f.endswith(f\"{difficulty}.pkl\"):\n",
    "            with open(f\"../data/processed_data/{f}\", 'rb') as d:\n",
    "                df = pickle.load(d)\n",
    "            seq = make_sequence(df)\n",
    "            corpus.append(seq)\n",
    "    MC = train_HMM(corpus, 5)\n",
    "    with open(f\"../models/HMM_{difficulty}.pkl\", 'wb') as f:\n",
    "        pickle.dump(MC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, whew, made it through the dealing with the \"version 1\" model. Now for the easy part! To train the second version of the HMM on the full dataset of maps with >70% rating, just run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulties = ['easy', 'normal', 'hard', 'expert', 'expertPlus']\n",
    "for difficulty in difficulties:\n",
    "    MC = HMM(difficulty)\n",
    "    with open(f\"../models/HMM_{difficulty}_v2.pkl\", 'wb') as f:\n",
    "        pickle.dump(MC, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BSmapsynth-env",
   "language": "python",
   "name": "bsmapsynth-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
